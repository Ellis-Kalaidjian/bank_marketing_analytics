---
title: "bank_marketing_analytics_model_comparison"
author: "Ellis Kalaidjian"
date: "6/14/2025"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Overview:
This document provides a comprehensive analysis of a bank marketing dataset, with the goal of predicting the success of marketing campaigns. Two main modeling approaches are employed: random forest classification and logistic regression. The initial random forest model performed well in predicting negative responses but struggled with positive predictions due to class imbalance. To address this, the analysis applied SMOTE (Synthetic Minority Over-sampling Technique), which significantly improved model performance—cutting the error rate and increasing the accuracy of predicting positive responses. Variable importance measures identified call duration as the strongest predictor, though its use is limited for forward-looking models since it is only known after contact. A logistic regression model was also implemented using standardized predictors, allowing for interpretable coefficients and odds ratios. Both models were evaluated using AUC from ROC curves, with high scores (0.9425 for random forest, 0.9291 for logistic regression), indicating strong predictive performance. Overall, the document outlines a robust and methodical approach to understanding and improving predictive marketing outcomes.

```{r}
#load packages
packages <- c('tidyr','dplyr','stats','ggplot2','randomForest',
          'pROC','themis','recipes','broom','knitr')
for (i in packages) {
  suppressPackageStartupMessages(library(i, character.only = T))} ; rm(i)
setwd("/Users/elliskalaidjian/Desktop/Data_Analyst_Portfolio/bank_marketing")

#load dataset
bank_market.df <- read.csv("./bank-additional/bank-additional-full.csv", sep = ";", stringsAsFactors = FALSE)

#view variables
str(bank_market.df)
```

This dataset contains 41,188 observations grouped over 21 variables of categorical, numeric, and binary classes. 

##DATA CLEANING AND TRANSFORMATION
```{r}
#check for NAs
colSums(is.na(bank_market.df))
```
No NAs in this dataset

```{r}
#create dummy variables for each categorical variable 
cat_vars <- names(bank_market.df[, c(2:10,15,21)])
bank_market.df.numeric <- bank_market.df %>%
  mutate(across(all_of(cat_vars), 
                ~ as.integer(factor(., levels = unique(.))), 
                .names = "{.col}_code"))
bank_market.df.numeric <- bank_market.df.numeric[, -c(2:10,15,21)] #remove categorical variables for which dummy variables were created
head(bank_market.df.numeric)
```

##EXPLORATORY DATA ANALYSIS
```{r}
#examine summary statistics 
for (var in names(bank_market.df.numeric)) {
  cat("Summary statistics for",var,":\n")
  print(summary(bank_market.df.numeric[[var]]))
  cat("\n")
}
```

```{r}
#create age categorization variable: young adult (17-25yrs); adult (26-44yrs); Middle-age (45-59yrs); Old age (60+yrs)
bank_market.df <- bank_market.df %>%
  mutate(age_grp = case_when(
    age <= 25 ~ "young adult",
    age >= 26 & age <= 44 ~ "adult",
    age >= 45 & age <= 59 ~ "middle-aged",
    age >= 60 ~ "old"))

#create totals tables for demographics
dem_vars <- c("age_grp","marital","job","education","housing","loan","default")
for (var in dem_vars) {
  df <- table(bank_market.df[[var]]) %>% sort(decreasing = T)
  assign(paste0(var, ".df"), df)
}

print(age.df)
print(marital.df)
print(job.df)
print(education.df)
print(housing.df)
print(loan.df)
print(default.df)
```

The sample exhibits a median age of 38 years old, with a majority of subjects (26,588) classified as "adult" (ages 26-44). Most subjects are married (24,928), work in administrative roles (10,422), and hold university degrees (12,168). Additionally, most have credit in default (32,588), a housing loan (21,576), and a personal loan (33,950).

```{r}
#visualize distributions of jobs and age 
age.jobs.df <- table(bank_market.df$age_grp, bank_market.df$job)
blue_shades <- colorRampPalette(c("lightblue", "blue4"))(nrow(age.jobs.df))
bp <- barplot(age.jobs.df,
              beside = TRUE,
              col = blue_shades,
              las = 2,
              font.axis = 1.2,
              cex.axis = 0.8,
              cex.names = 0.75)
legend(x = 25,
       y = 7500,
       legend = rownames(age.jobs.df),
       fill = blue_shades,
       bty = "n",
       cex = 0.8,
       x.intersp = 0.2)
```

##RANDOM FOREST CLASSIFICATION
```{r}
set.seed(123)

#split data into training and test sets. sample 70% of the data for training
train_index <- sample(seq_len(nrow(bank_market.df.numeric)), size = 0.7 * nrow(bank_market.df.numeric))
rf_train <- bank_market.df.numeric[train_index, ]
rf_test  <- bank_market.df.numeric[-train_index, ]

#fit the Random Forest model on training dataset
rf.model <- randomForest(factor(y_code) ~ ., data = rf_train, importance = TRUE)

summary(rf.model)
```
While the model exhibits a very low Out-of-Bounds error rate and predicts the response of “no” quite well, it incorrectly predicts yes about 50% of the time. This likely stems from an imbalance in “no” versus “yes responses”. A quick look at the counts of each response reveals that imbalance is likely troubling the model.

```{r}
ggplot(bank_market.df, aes(x=y)) +
  geom_bar(fill = "steelblue", color = "black") +
  labs(x="Did Respondent Buy Long-term Deposit?") +
  theme_minimal()
```
It's apparent that the data are largely imbalanced on "NO" responses. So we need to use the SMOTE oversampling method to address this.

```{r}
#SMOTE oversampling
#look at counts of No's and Yes's to determine over and under criteria for smote based on a 60/40 split
table(bank_market.df$y)
```
Let T = total number of observations after SMOTE
Then:yes = 0.4 × T and no = 0.6 × T = 36,548
So: T = 36,548 / 0.6 = 60,913
Desired yes = 0.4 × 60,913 = 24,365
Currently have 4,640 "yes", so you need synthetic samples: 24,365 − 4,640 = 19,725
Now calculate the over_ratio. In step_smote(), the over_ratio is defined as:
over_ratio = desired_total_minority / original_minority.
Hence, over_ratio = 24,365 / 4,640 ≈ 5.25

```{r}
# Build recipe for training the data
smote_recipe <- recipe(y_code ~ ., data = rf_train) %>%
  step_smote(y_code, over_ratio = 5.25)

# Prep and apply
smote_prepped <- prep(smote_recipe)
rf_train.smote <- juice(smote_prepped)

# pass rf_train.smote through RF 
set.seed(123)
rf.model.smote <- randomForest(factor(y_code) ~ ., data = rf_train.smote, importance = TRUE)
summary(rf.model.smote)
```
After adjusting for imbalance via SMOTE, the predictive capacity of the model increases substantially. Additionally, the OOB error rate drops from 8.52% to 1.96%.

```{r}
#Validating the RF model by calculating the area under the receiver operating characteristic curve (AUC-ROC)

#generate predicted probabilities on the test set
rf_pred_probs <- predict(rf.model, rf_test, type = "prob")[, 2]  # probs for class "2" (or "yes")

#prepare actual values from the test set
actual <- as.numeric(rf_test$y_code) - 1  # Convert to numeric 0/1

#evaluate on the original test set
rf_pred_probs <- predict(rf.model.smote, newdata = rf_test, type = "prob")
predicted_class <- predict(rf.model.smote, newdata = rf_test)

# Confusion matrix
table(Predicted = predicted_class, Actual = rf_test$y_code)

# ROC-AUC
roc_obj <- roc(rf_test$y_code, rf_pred_probs[, "2"])
auc(roc_obj)
#plot
plot(roc_obj, col = "blue", main = "ROC Curve for Random Forest Classification")
```
Very strong AUC-ROC value of 0.94

##LOGISTIC REGRESSION

```{r}
#Given that each variable is measured on different scales, the z-scores of each variable were computed to allow for comparison
df.standardized <- scale(bank_market.df.numeric[, -which(names(bank_market.df.numeric) == "y_code")])
df.standardized <- as.data.frame(df.standardized)
df.standardized$y_code <- bank_market.df.numeric$y_code

#split data into training and test sets
train_index_log <- sample(seq_len(nrow(df.standardized)), size = 0.7 * nrow(bank_market.df.numeric))
log_train <- df.standardized[train_index_log, ]
log_test  <- df.standardized[-train_index_log, ]

#Fit the logistic regression model on the training dataset
model.logit <- glm(factor(y_code) ~ ., data = log_train, family = binomial)
summary(model.logit)
```

```{r}
#output as table
tidy_table <- tidy(model.logit)
write.csv(tidy_table, "logit_output.csv", row.names = FALSE)

knitr::include_graphics("/logit_output.png")
```
Takeaways from the model---
Strong positive effects:
o	Contact duration increases odds of campaign success by 226%
o	Macroeconomic conditions, as measured through the consumer price and consumer confidence indices in particular, have notable impact on odds of campaign success
o	Month of the year and contact method have modest boosts on odds of campaign success
Strong negative effects:
o	Employment variation rate more than halves the odds of success (–57%)
o	default_code (–33%)
o	poutcome_code (–21%)
o	euribor3m (–15%)

```{r}
#calculate McFadden's Pseudo R-Squared
ll.null <- model.logit$null.deviance/-2 #calculate log-likelihood of null model
ll.proposed <-model.logit$deviance/-2 # calculate log-likelihood of model.logit
(ll.null - ll.proposed) / ll.null
```
Interpretation: McFadden's Pseudo R-Squared Value of 0.393212 is strong

```{r}
# calculate p-value of R-Squared
1 - pchisq(2*(ll.proposed - ll.null), df=(length(model.logit$coefficients)-1))
```
Interpretation: the model is statistically significant

```{r}
#Validating the logistic model by calculating the area under the receiver operating characteristic curve (AUC-ROC)
log_pred_probs <- predict(model.logit, newdata = log_test, type = "response")
actual <- as.numeric(log_test$y_code) - 1  # Converts factor levels to 0/1
roc_obj <- roc(actual, log_pred_probs)
auc(roc_obj)

#plot
plot(roc_obj, col = "blue", main = "ROC Curve for Logistic Regression")
```
This model also strongly predicts campaign response, however its slightly lower AUC-ROC value of 0.9291 renders the RF model superior